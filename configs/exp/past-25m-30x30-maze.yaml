# @package _global_

defaults:
  - override /dataset: maze
  - override /model: past
  - override /mode: cluster

model:
  attn_sink: False
  bias: True
  dropout: 0
  n_embd: 256
  n_head: 4
  n_layer: 16
  scale_loss: False
  stack_enc_dec: True
  tie_lmhead: True
  train_mode: absorbing
  vocab_size: 64

optim:
  learning_rate: 0.001
  warmup_pct: 0.05

datamodule:
  batch_size: 4
  grid_n: 30
  n_mazes: 100000

trainer:
  check_val_every_n_epoch: 50
  max_epochs: 2000
  num_sanity_val_steps: 0
  accumulate_grad_batches: 4

nodes: 16
