# @package _global_

defaults:
  - override /dataset: maze
  - override /model: past
  - override /mode: cluster

model:
  attn_sink: False
  bias: True
  dropout: 0
  n_embd: 128
  n_head: 4
  n_layer: 7
  scale_loss: False
  stack_enc_dec: True
  tie_lmhead: True
  train_mode: absorbing
  vocab_size: 64

optim:
  learning_rate: 0.001
  warmup_pct: 0.05

datamodule:
  batch_size: 16 # nodes = 2
  grid_n: 20
  n_mazes: 100000

trainer:
  check_val_every_n_epoch: 100
  max_epochs: 2500
  
nodes: 2
