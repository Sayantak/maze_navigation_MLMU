# @package _global_

defaults:
  - override /dataset: maze
  - override /model: past

model:
  attn_sink: False
  bias: True
  dropout: 0
  n_embd: 128
  n_head: 4
  n_layer: 4
  scale_loss: False
  stack_enc_dec: True
  tie_lmhead: True
  train_mode: absorbing
  vocab_size: 64

optim:
  learning_rate: 0.001
  warmup_pct: 0.05

datamodule:
  batch_size: 256
  grid_n: 3
  n_mazes: 40000

trainer:
  check_val_every_n_epoch: 10
  max_epochs: 300
